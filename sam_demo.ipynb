{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T18:28:04.902947Z",
     "start_time": "2025-05-09T18:28:01.857004Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "print(torch.cuda.is_available())\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T21:06:38.636200Z",
     "start_time": "2025-05-05T21:06:37.304323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#crop face\n",
    "# Load image\n",
    "image = cv2.imread(\"./assets/jonas.jpg\")\n",
    "output_width, output_height = 400, 500\n",
    "corner_radius = 80  # pixels\n",
    "\n",
    "# Load image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load Haar cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "if len(faces) == 0:\n",
    "    raise Exception(\"No face detected!\")\n",
    "\n",
    "# Choose the first face\n",
    "(x, y, w, h) = faces[0]\n",
    "\n",
    "# Define crop region centered around face with desired aspect ratio\n",
    "center_x, center_y = x + w // 2, y + h // 2\n",
    "desired_ratio = output_width / output_height\n",
    "\n",
    "# Compute crop size keeping aspect ratio\n",
    "if w / h > desired_ratio:\n",
    "    crop_h = h\n",
    "    crop_w = int(h * desired_ratio)\n",
    "else:\n",
    "    crop_w = w\n",
    "    crop_h = int(w / desired_ratio)\n",
    "\n",
    "# Expand the crop slightly for better framing\n",
    "scale = 1.6\n",
    "crop_w = int(crop_w * scale)\n",
    "crop_h = int(crop_h * scale)\n",
    "\n",
    "# Get top-left corner of crop\n",
    "x1 = max(0, center_x - crop_w // 2)\n",
    "y1 = max(0, center_y - crop_h // 2)\n",
    "x2 = min(image.shape[1], x1 + crop_w)\n",
    "y2 = min(image.shape[0], y1 + crop_h)\n",
    "\n",
    "# Crop and resize\n",
    "cropped = image[y1:y2, x1:x2]\n",
    "resized = cv2.resize(cropped, (output_width, output_height))\n",
    "\n",
    "# Create rounded corner mask\n",
    "mask = np.zeros((output_height, output_width), dtype=np.uint8)\n",
    "cv2.rectangle(mask, (0, 0), (output_width, output_height), 255, -1)\n",
    "\n",
    "# Rounded rectangle via Gaussian blur\n",
    "ksize = corner_radius if corner_radius % 2 == 1 else corner_radius + 1\n",
    "mask = cv2.GaussianBlur(mask, (ksize, ksize), 0)\n",
    "\n",
    "# Merge with alpha channel\n",
    "rounded = cv2.cvtColor(resized, cv2.COLOR_BGR2BGRA)\n",
    "rounded[:, :, 3] = mask\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"results/rounded_face.png\", rounded)"
   ],
   "id": "a1d7110adcfa591f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T21:32:14.786485Z",
     "start_time": "2025-05-05T21:32:05.809218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mouse_callback(event, x, y, flags, param):\n",
    "    # if event == cv2.EVENT_MOUSEMOVE:\n",
    "    #     print(f\"Mouse moved to: ({x}, {y})\")\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f\"Left button clicked at: ({x}, {y})\")\n",
    "\n",
    "# Load and show image\n",
    "image = cv2.imread(\"assets/generated.png\")\n",
    "image = cv2.resize(image, (1600, 1200))\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", mouse_callback)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC key to exit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "2219373a189f545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left button clicked at: (153, 158)\n",
      "Left button clicked at: (635, 704)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[70], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage\u001B[39m\u001B[38;5;124m\"\u001B[39m, image)\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m27\u001B[39m:  \u001B[38;5;66;03m# ESC key to exit\u001B[39;00m\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     18\u001B[0m cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T21:40:01.974402Z",
     "start_time": "2025-05-05T21:40:01.872096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merge images\n",
    "# Load background image\n",
    "background = cv2.imread(\"assets/generated.png\", cv2.IMREAD_COLOR)\n",
    "background = cv2.resize(background, (1600, 1200))\n",
    "# Load foreground (headshot) image with alpha channel\n",
    "foreground = cv2.imread(\"results/rounded_face.png\", cv2.IMREAD_UNCHANGED)  # BGRA\n",
    "\n",
    "# Resize foreground to fit specified area\n",
    "x1, y1 = 153, 158\n",
    "x2, y2 = 635, 704\n",
    "target_width = x2 - x1\n",
    "target_height = y2 - y1\n",
    "foreground = cv2.resize(foreground, (target_width, target_height))\n",
    "\n",
    "# Separate channels\n",
    "fg_rgb = foreground[:, :, :3]\n",
    "fg_alpha = foreground[:, :, 3] / 255.0\n",
    "fg_alpha = fg_alpha[..., np.newaxis]  # shape (h, w, 1)\n",
    "\n",
    "# Get ROI from background\n",
    "roi = background[y1:y2, x1:x2]\n",
    "\n",
    "# Blend foreground and ROI\n",
    "blended = (fg_rgb * fg_alpha + roi * (1 - fg_alpha)).astype(np.uint8)\n",
    "\n",
    "# Put blended region back to background\n",
    "background[y1:y2, x1:x2] = blended\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "color = (255, 255, 255)  # White color\n",
    "cv2.putText(background, \"CEO Jonas\", (100, 850), font, 5, color, 20, cv2.LINE_AA)\n",
    "# Save or show\n",
    "cv2.imwrite(\"results/final_composite.jpg\", background)"
   ],
   "id": "62d41da41b3177cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:37:17.145566Z",
     "start_time": "2025-05-09T18:37:15.573103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load image\n",
    "image = cv2.imread(\"./assets/Vehicle_img2.jpg\")\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Load SAM model\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"models/sam_vit_b_01ec64.pth\")\n",
    "sam.to(\"cuda\")  # or \"cpu\" if you don't have a GPU\n",
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(image_rgb)\n",
    "\n",
    "# User-provided foreground point (example: adjust as needed to a point on the car)\n",
    "input_point = np.array([[image.shape[1]//2, image.shape[0]//2]])  # Approx center of image\n",
    "input_label = np.array([1])  # 1 = foreground\n",
    "\n",
    "# Predict mask\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=True,\n",
    ")\n",
    "# Choose the best mask based on score\n",
    "best_idx = np.argmax(scores)\n",
    "mask = masks[best_idx].astype(np.uint8)\n",
    "# Get the predicted mask (foreground = car)\n",
    "# mask = masks[0].astype(np.uint8)\n",
    "\n",
    "# Convert image to BGRA\n",
    "rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "# Set alpha channel: transparent for background (0), opaque for car (1)\n",
    "rgba[:, :, 3] = mask * 255  # Keep car, make rest transparent\n",
    "\n",
    "# Save the output image\n",
    "cv2.imwrite(\"results/sam_car_only.png\", rgba)"
   ],
   "id": "b6121daad6bdceb9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:24:30.165015Z",
     "start_time": "2025-05-05T08:24:28.473902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merge result images\n",
    "\n",
    "fg = cv2.imread(\"results/sam_background_only.png\", cv2.IMREAD_UNCHANGED)  # includes alpha\n",
    "\n",
    "\n",
    "# Load the background image\n",
    "bg = cv2.imread(\"assets/background.jpg\")\n",
    "\n",
    "# Resize the foreground maintaining aspect ratio\n",
    "h, w = fg.shape[:2]\n",
    "aspect_ratio = w / h\n",
    "bg_h, bg_w = bg.shape[:2]\n",
    "\n",
    "# Calculate new dimensions for foreground\n",
    "if aspect_ratio > bg_w / bg_h:\n",
    "    new_w = bg_w\n",
    "    new_h = int(bg_w / aspect_ratio)\n",
    "else:\n",
    "    new_h = bg_h\n",
    "    new_w = int(bg_h * aspect_ratio)\n",
    "\n",
    "fg_resized = cv2.resize(fg, (new_w, new_h))\n",
    "\n",
    "# Create a new blank canvas with the background size\n",
    "pad_top = (bg_h - new_h) // 2\n",
    "pad_left = (bg_w - new_w) // 2\n",
    "\n",
    "# Create a padded foreground\n",
    "padded_fg = np.zeros((bg_h, bg_w, 4), dtype=np.uint8)\n",
    "padded_fg[pad_top:pad_top+new_h, pad_left:pad_left+new_w] = fg_resized\n",
    "\n",
    "# Split the padded foreground\n",
    "b, g, r, a = cv2.split(padded_fg)\n",
    "\n",
    "# Normalize the alpha mask\n",
    "alpha = a.astype(float) / 255\n",
    "alpha = np.stack([alpha] * 3, axis=-1)\n",
    "\n",
    "# Perform alpha blending: Merge foreground with background\n",
    "fg_rgb = cv2.merge([b, g, r])\n",
    "result = (fg_rgb * alpha + bg * (1 - alpha)).astype(np.uint8)\n",
    "\n",
    "# Save the final merged result\n",
    "cv2.imwrite(\"results/merged_result_with_padding.jpg\", result)"
   ],
   "id": "48b52b8968a35f8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:24:32.892459Z",
     "start_time": "2025-05-05T08:24:32.066663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"CEO Jonas\"\n",
    "height, width, _ = result.shape\n",
    "\n",
    "# Dynamically set font scale based on image height\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = height / 600  # Tune this ratio for your preferred size\n",
    "thickness = int(height / 300)  # Adjust thickness relative to image height\n",
    "color = (255, 255, 255)  # White color\n",
    "\n",
    "# Get text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "text_width, text_height = text_size\n",
    "\n",
    "# Calculate centered position\n",
    "x = (width - text_width) // 2\n",
    "y =  height - text_height\n",
    "\n",
    "# Optional: Add dark rectangle background behind text\n",
    "rect_padding = 10\n",
    "cv2.rectangle(\n",
    "result,\n",
    "(x - rect_padding, y - text_height - rect_padding),\n",
    "(x + text_width + rect_padding, y + rect_padding),\n",
    "(0, 255, 0),  # Black background\n",
    "cv2.FILLED\n",
    ")\n",
    "\n",
    "# Put text on image\n",
    "cv2.putText(result, text, (x, y), font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite(\"results/image_with_text.png\", result)"
   ],
   "id": "f94be6b1783ce92f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "296c581b3b2360be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
